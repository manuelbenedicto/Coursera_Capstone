{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Paris Boroughs Cluster Classification Using K-means\n\n## Applied Data Science Capstone\n\n### This notebook is the final project of IBM's Data Science Professional Certificate"},{"metadata":{},"cell_type":"markdown","source":"## Table of contents\n* [Introduction](#introduction)\n* [Data](#data)\n* [Methodology](#methodology)\n* [Analysis](#analysis)\n* [Results and Discussion](#results)\n* [Conclusion](#conclusion) "},{"metadata":{},"cell_type":"markdown","source":"## Introduction <a name=\"introduction\"></a>"},{"metadata":{},"cell_type":"markdown","source":"For many people, the search for an excellent area to live is an arduous process of investigation into the different areas of one city. The definition of a good area to live into varies from one person to another and so the search for a house or an apartment is in the same way unique to the individual.\n \nIn this project we will try to find an optimal neighborhood for a fictional client. This client will have some criteria that will define their ideal area to live in Paris (France). These are the three elements our client wants us to take into account to do our search:\n\n* The apartment should be near a pharmacy\n* It should also have a grocery nearby\n* And it should not be far from a metro or train station"},{"metadata":{},"cell_type":"markdown","source":"## Data <a name=\"data\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Based on the problem we are trying to solve we will need geospatial data such as the list of neighborhoods in Paris and their latitude and longitude coordinates. Also, we will need venue data in relation to the criteria of the ideal area to live given by the user.\n\nFollowing data sources will be needed to extract/generate the required information:\n* coordinate of each parisian borough will be extracted from the French government's **[Open Platform for French Public Data](https://www.data.gouv.fr/en/datasets/quartiers-administratifs/)**\n* number of pharmacies, groceries and metro stations and their location in every neighborhood will be obtained using **Yelp API**\n\n"},{"metadata":{},"cell_type":"markdown","source":"### *Quartiers* of Paris"},{"metadata":{},"cell_type":"markdown","source":"In order to visualize in a map the boroughs later in our analysis, now we are going to extract the data of their shapes and coordinates from the French government's database."},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"# Let's import all the necessary packages to work with our data\n\nimport numpy as np\nimport pandas as pd\nimport shapely\nimport descartes\nimport geopandas as gpd\nimport json\nimport os\nimport requests\nimport folium\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nimport seaborn as sns\n\n# Let's import the dataset of the parisian boroughs' coordinates as a dataframe with geopandas\n\nboroughs_url = 'https://www.data.gouv.fr/es/datasets/r/a8748f53-5850-4a04-b8cc-9c9f5f72949f'\nboroughs = gpd.read_file(boroughs_url)\nboroughs.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This dataset gives us an overview of how the boroughs in Paris are shaped. In fact, they are shaped as polygons and there are 80 of them. In order to be able to work better on this data we are going to add centroids to each borough which will serve us to look for venues around them. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create a new dataset with geopandas adding centroids to each borough\n\nboroughs = gpd.GeoDataFrame.from_features(boroughs)\nboroughs['centroid_lon'] = boroughs['geometry'].centroid.x\nboroughs['centroid_lat'] = boroughs['geometry'].centroid.y\nboroughs = boroughs.sort_values(by=['l_qu'])\nboroughs.crs = {'init': 'epsg:4326'}\nboroughs.to_csv(path_or_buf='boroughs.csv')\npd.read_csv('boroughs.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Retrieving venues using Yelp's API"},{"metadata":{},"cell_type":"markdown","source":"In this project we will direct our efforts on finding a borough that fits the criteria given by our client. We will consider those that have the more venues related to the client's needs as the best boroughs.\n\nFirst of all, we are going to collect the data required for our analysis: location of every pharmacy, supermarket and metro station within every *quartier* in the city of Paris. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"API_KEY\")\nsecret_value_1 = user_secrets.get_secret(\"appID\")\nheaders = {'Authorization': 'Bearer %s' % secret_value_0}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's build a new dataframe with the venues that match the criteria of our client\n\n# We create two functions to retrieve the data from Yelp's website\n\nurl = 'https://api.yelp.com/v3/businesses/search?'\n\ncategory = ['pharmacy', 'grocery', 'metrostations']\ncategories = ','.join(category)\n\n# The first function will create all the API url requests\n\ndef defparams(lat, lon, radius, categories):\n    params = {}\n    params['latitude'] = lat\n    params['longitude'] = lon\n    params['radius'] = 1000\n    params['categories'] = categories\n    params['limit']=50\n    return params\n\n# This function will iterate through each borough to find nearby venues according to the defined criteria\nnames = boroughs['l_qu']\nlatitudes = boroughs['centroid_lat']\nlongitudes = boroughs['centroid_lon']\n\ndef getnearbyvenues (names, latitudes, longitudes, radius=1000, limit=50):\n    venues_list = []\n    for name, lat, lon in zip(names, latitudes, longitudes):\n        params = defparams(lat, lon, radius, categories)\n        results = requests.get(url=url, params=params, headers=headers).json()['businesses']\n        \n        for item in results:\n            venue_name = item['name']\n            venue_category = item['categories'][0]['title']\n            venue_lat = item['coordinates']['latitude']\n            venue_lon = item['coordinates']['longitude']\n            try:\n                venue_city = item['location']['city']\n            except:\n                venue_city = 'N/A'\n            venues_list.append([(name,\n                                lat,\n                                lon,\n                                venue_name,\n                                venue_category,\n                                venue_lat,\n                                venue_lon,\n                                venue_city)])\n    nearbyvenues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearbyvenues.columns = ['Borough',\n                           'Borough Latitude',\n                           'Borough Longitude',\n                           'Venue Name',\n                           'Venue Category',\n                           'Venue Latitude',\n                           'Venue Longitude',\n                           'Venue City']\n    return nearbyvenues\n\nvenue_data = getnearbyvenues(boroughs['l_qu'], boroughs['centroid_lat'], boroughs['centroid_lon'], radius=5000, limit=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to not make calls to the API each time we run our code we are going to create a CSV file that collects all the data that has been retrieved."},{"metadata":{"trusted":true},"cell_type":"code","source":"venue_data.to_csv(path_or_buf='venue_data.csv')\npd.read_csv('venue_data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Data preprocessing and data cleaning**"},{"metadata":{},"cell_type":"markdown","source":"The dataset we are using for our analysis is slightly large and might contain some null values or data we are not interested in. The code below is useful to get a first approach to our dataframe and clean the data to be able to do a better analysis.\n\n* What cities are the venues located in?\n\nThe first question that pops up is if all the elements are within the limits of the city of Paris. In order to verify that we are going to use the pandas function groupby to look for venues that do not belong to our analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"venue_data.groupby('Venue City')['Venue City'].count().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the requests from the Yelp's API have delivered us some elements that are not interesting in terms of being part of our analysis. We are going to take into account only those elements that in the category city belong to 'Paris', 'Paris 18', 'Paris 10', 'Paris 15'."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's drop the venues that do not interest us from the dataframe and rename some so as that 'Paris' is the only value on the column 'Venue City'\n\nparis_venues = venue_data[(venue_data['Venue City'] == 'Paris') | \n                          (venue_data['Venue City'] == 'Paris 18') | \n                          (venue_data['Venue City'] == 'Paris 10') | \n                          (venue_data['Venue City'] == 'Paris 15')]\nparis_venues['Venue City'].replace(to_replace='Paris 18', value='Paris', inplace=True)\nparis_venues['Venue City'].replace(to_replace='Paris 10', value='Paris', inplace=True)\nparis_venues['Venue City'].replace(to_replace='Paris 15', value='Paris', inplace=True)\ninfo = venue_data.shape[0] - paris_venues.shape[0]\nprint(f'{info} entries were removed from the original dataset based on \"Venue City\"')\nparis_venues.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* How many types of venues are we getting?\n\nWe are going to look into the categories of our collected venues as it might be the case that we have some venues that should not be in the dataframe for our analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"unique = len(paris_venues['Venue Category'].unique())\nprint(f'There are {unique} venue categories in this dataframe')\nparis_venues.groupby('Venue Category')['Venue Category'].count().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the purpose of simplicity and more accuracy, we are going to only take into further analysis the venues that are part of the categories 'Grocery', 'Pharmacy' and 'Metro Stations' and 'Train Stations'."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's drop all the venues from categories that will not be part of our analysis\ncategories_for_analysis = ['Grocery', 'Pharmacy', 'Metro Stations', 'Train Stations']\nparis_venues_final = paris_venues[paris_venues['Venue Category'].isin(categories_for_analysis)]\ninfo = paris_venues.shape[0] - paris_venues_final.shape[0]\nprint(f'{info} venues were deleted from the dataset to simplify the categories')\nparis_venues_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the sake of simplicity, we are going to combine the categories 'Metro Stations' and 'Train Stations' into 'Metro/Train Station'."},{"metadata":{"trusted":true},"cell_type":"code","source":"paris_venues_final['Venue Category'].replace(to_replace='Metro Stations', value='Metro/Train Station', inplace=True)\nparis_venues_final['Venue Category'].replace(to_replace='Train Stations', value='Metro/Train Station', inplace=True)\nparis_venues_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Are there any null values in our dataset?"},{"metadata":{"trusted":true},"cell_type":"code","source":"paris_venues_final.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As there is none we are not going to have to delete more data from our dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's figure out the final shape of our dataframe\nprint(f'{paris_venues_final.shape} is the shape in columns and rows for our dataset after the data cleaning')\n# Let's create a new file containing the new dataset\nparis_venues_final.to_csv(path_or_buf='paris_venues.csv')\nprint('A new csv file called \"paris_venues\" has been created')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Methodology <a name=\"methodology\"></a>"},{"metadata":{},"cell_type":"markdown","source":"In this project we will direct our efforts on detecting areas of Paris that have high pharmacy, supermarket and metro station density, criteria given by our client that is looking for an apartment nearby these type of venues.\n\nIn first step we have collected the required data: location and limits of every borough of Paris and venues inside each borough. We have used a dataset provided by the French government to know the shape of each borough in the city of Paris and afterwards we have collected the data related to the venues with the Yelp's API.\n\nLater on we have pursued the analysis of the data related to the venues in each borough. First of all we have created a new dataframe containing the total number of each type of venue in order to plot the data into some graphics to have an idea of the boroughs with higher density in each type of venue.\n\nWe are now able to visualize the location of each type of venue in a map along with the centroid of each borough so that in a brief look we can figure out what areas fit our search criteria.\n\nThis visualization helps us formulate a hypothesis about the ideal boroughs for our client. We are going to create clusters using k-means clustering to identify boroughs that are most populated with the venues we have picked as our criteria to find the best borough to live in. \n\nWith a boxplot we are going to see which cluster is the one that is more crowded with those venues and finally we are going to see which boroughs belong to each cluster and how many venues those boroughs have in a new map. "},{"metadata":{},"cell_type":"markdown","source":"## Analysis <a name=\"analysis\"></a>"},{"metadata":{},"cell_type":"markdown","source":"In order to use Yelpâ€™s category values the boroughs in Paris with highest density of the venues set by our client, we are going to create a one-hot-encoding representation of each entry using Pandas' 'get_dummies' function."},{"metadata":{"trusted":true},"cell_type":"code","source":"paris_venues_onehot = pd.get_dummies(paris_venues_final[['Venue Category']], prefix='', prefix_sep='')\nparis_venues_onehot['Borough'] = paris_venues_final['Borough']\n\nfixed_columns = [paris_venues_onehot.columns[-1]] + list(paris_venues_onehot.columns[:-1])\nparis_venues_onehot = paris_venues_onehot[fixed_columns]\n\nprint(paris_venues_onehot.shape)\nparis_venues_onehot.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are going to determine the total number of venues in each borough."},{"metadata":{"trusted":true},"cell_type":"code","source":"venue_counts = paris_venues_onehot.groupby('Borough').sum()\nvenue_counts.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the DataFrame of venue counts shown above, we are going to create horizontal bar plots for our three venue categories to help visualize the top 25 neighborhoods in regards to each particular venue. We use the following loop and matplotlib library to iterate through all categories and visualize the results:"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 25\nplot_categories = ['Grocery', 'Metro/Train Station', 'Pharmacy']\nfor category in plot_categories:\n    plt.figure(num=None, figsize=(12, 7), dpi=80, facecolor='w', edgecolor='k')\n    plt.title(f'Top {n} Boroughs with higher density of {category}')\n    top_category_boroughs = venue_counts[category].sort_values(ascending=False)[0:n]\n    top_category_boroughs = top_category_boroughs.sort_values(ascending=True)\n    top_category_boroughs.plot.barh(y=category, rot=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are going to visualize the data related to the venues in a map rendered with Folium's library to formulate a first hypothesis about the boroughs that suit our criteria the most."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create a map with the limits of each parisian borough\n\nm = folium.Map(location=[np.median(boroughs['centroid_lat'].tolist()),\n                         np.median(boroughs['centroid_lon'].tolist())],\n               tiles='Stamen Toner', zoom_start=11.6)\n\nfolium.GeoJson(boroughs, name='Borough Limits').add_to(m)\n\n# We are going to add black circle markers representing the centroids of each borough \n\nfg = folium.FeatureGroup(name='Borough Info')\nfor clat, clon, name, in zip(boroughs['centroid_lat'].tolist(),\n                             boroughs['centroid_lon'].tolist(),\n                             boroughs['l_qu'].tolist()):\n    html = f\"\"\"\n    <b>{name}</b>\n    \"\"\"\n    \n    fg.add_child(folium.CircleMarker(location=[clat, clon], popup=html, radius=5, \n                                     color='black', fill=True, fill_color='black', \n                                     fill_opacity=0.8))\n\n    m.add_child(fg)\n\n# We will now add circle markers for each type of venue\n\nfg = folium.FeatureGroup(cat='Venue Category')\nfor lat, lon, cat in zip(paris_venues_final['Venue Latitude'].tolist(),\n                        paris_venues_final['Venue Longitude'].tolist(),\n                        paris_venues_final['Venue Category'].tolist()):\n    if cat == 'Grocery':\n        folium.CircleMarker(location=[lat, lon], radius=3, color='yellow',\n                            fill = True, fill_color='yellow', fill_opacity=0.6).add_to(fg)\n    elif cat == 'Pharmacy':\n        folium.CircleMarker(location=[lat,lon], radius=3, color='green',\n                            fill=True, fill_color='green', fill_opacity=0.6).add_to(fg)\n    else: # Every other venue marker is thus a metro or train station\n        folium.CircleMarker(location=[lat, lon], radius=3, color='red',\n                            fill=True, fill_color='red', fill_opacity=0.6).add_to(fg)\n\n    m.add_child(fg)\n\ndef embed_map(m):\n    from IPython.display import HTML\n\n    m.save('index.html')\n    with open('index.html') as f:\n        html = f.read()\n\n    iframe = '<iframe srcdoc=\"{srcdoc}\" style=\"width: 100%; height: 750px; border: none\"></iframe>'\n    srcdoc = html.replace('\"', '&quot;')\n    return HTML(iframe.format(srcdoc=srcdoc))\n\n\nembed_map(m)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At glance we could say that northern and central boroughs look like the most crowded in venues specified by our client. We are going to check that premise through the machine learning algorithm of k-means clustering."},{"metadata":{},"cell_type":"markdown","source":"### Data preparation"},{"metadata":{},"cell_type":"markdown","source":"Let's normalize the data using MinMaxScaler (scale from 0 to 1). This scales the data and provides an easy to interpret score at the same time."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nX = pd.DataFrame(venue_counts)\nX = X.values\ncluster_dataset = MinMaxScaler().fit_transform(X)\n\ncluster_df = pd.DataFrame(cluster_dataset)\ncluster_df.columns = [c for c in plot_categories]\ncluster_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Clustering\n\nWe'll be using k-means clustering for our analysis. These were preliminary results with different number of clusters:\n\n* 2 clusters only show the uptown/downtown divide of the boroughs\n* 3 clusters give more accuracy to our model but is not divided enough\n* 4 clusters also identify neighborhoods with very low density of venues and gives to our model more accuracy\n* 5 clusters and more create more groups than needed for our general analysis \n\nFor this data analysis we are going to use 4 clusters as we think is the number that might fit the most our dataset and the results we are looking for."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Let's set number of clusters and run the k-means algorithm\nkclusters = 4\n\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(cluster_df)\n\nkmeans_labels = kmeans.labels_\n\n# Let's change label numbers so they go from highest scores to lowest\n\nreplace_labels = {0:2, 1:0, 2:3, 3:1}\n\nfor i in range(len(kmeans_labels)):\n    kmeans_labels[i] = replace_labels[kmeans_labels[i]]\n\nvenue_clusters = venue_counts.copy()\nvenue_clusters['Cluster'] = kmeans_labels\nvenue_clusters_minmax_df = cluster_df.copy()\nvenue_clusters_minmax_df['Borough'] = pd.read_csv('boroughs.csv')['l_qu']\nvenue_clusters_minmax_df['Cluster'] = kmeans_labels\nvenue_clusters_minmax_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's use matplotlib library to create a boxplot to visualize the different clusters and see which one represents the boroughs with the highest density in venues specified by our client."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.ticker as ticker\n\nfig, axes = plt.subplots(1, kclusters, figsize=(20, 10), sharey=True)\n\naxes[0].set_ylabel('Count of venues (relative)', fontsize=25)\n\nfor k in range(kclusters):\n    # We are going to set same y axis limits\n    axes[k].set_ylim(0,1.1)\n    axes[k].xaxis.set_label_position('top')\n    axes[k].set_xlabel('Cluster ' + str(k), fontsize=25)\n    axes[k].tick_params(labelsize=20)\n    plt.sca(axes[k])\n    plt.xticks(rotation='vertical')\n    sns.boxplot(data = venue_clusters_minmax_df[venue_clusters_minmax_df['Cluster'] == k].drop('Cluster',1), ax=axes[k])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see in our boxplot the cluster of boroughs with higher density of the venues defined by our criteria is cluster number 2 and is followed by the cluster number 1. \n\nWe are going to add to the previous dataframe the latitude and longitude coordinates of each borough so that we can represent them in a map created with Python's folium library."},{"metadata":{"trusted":true},"cell_type":"code","source":"venue_clusters_minmax_df['Latitude'] = pd.read_csv('boroughs.csv')['centroid_lat']\nvenue_clusters_minmax_df['Longitude'] = pd.read_csv('boroughs.csv')['centroid_lon']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's visualize the clustered neighbors in our new map. We will add circle markers to each borough centroid so that we can see how many venues are in each borough and to wich cluster it belongs to. \n\n* Cluster number 0 is represented by red\n* Cluster number 1 is represented by orange \n* **Cluster number 2** is represented by **green**\n* Cluster number 3 is represented by blue"},{"metadata":{"trusted":true},"cell_type":"code","source":"m_clusters = folium.Map(location=[np.median(boroughs['centroid_lat'].tolist()),\n                         np.median(boroughs['centroid_lon'].tolist())], \n                        tiles = 'Stamen Toner', zoom_start=11.6)\n\nfolium.GeoJson(boroughs, name='Borough Limits').add_to(m_clusters)\n\n# Let's add markers for each borough\n\nfor i, borough, lat, lon, cluster, gr, ph, mt in zip(venue_clusters_minmax_df.index,\n                                                     venue_clusters_minmax_df['Borough'],\n                                                     venue_clusters_minmax_df['Latitude'],\n                                                     venue_clusters_minmax_df['Longitude'],\n                                                     venue_clusters_minmax_df['Cluster'],\n                                                     pd.DataFrame(venue_counts)['Grocery'],\n                                                     pd.DataFrame(venue_counts)['Pharmacy'],\n                                                     pd.DataFrame(venue_counts)['Metro/Train Station']):  \n    popup='<b>{}</b> is part of Cluster {} with {} groceries, {} pharmacies and {} metro or train/stations'.format(\n        borough, cluster, gr, ph, mt)\n    if cluster == 0:\n        folium.CircleMarker(location=[lat,lon], radius=5, popup=folium.Popup(popup,max_width=300),\n                           color='red', fill=True, fill_color='red', fill_opacity=0.6).add_to(m_clusters)\n    elif cluster == 1:\n        folium.CircleMarker(location=[lat,lon], radius=5, popup=folium.Popup(popup, max_width=300),\n                           color='orange', fill=True, fill_color='orange', fill_opacity=0.6).add_to(m_clusters)\n    elif cluster == 2:\n        folium.CircleMarker(location=[lat,lon], radius=5, popup=folium.Popup(popup, max_width=300),\n                           color='green', fill=True, fill_color='green', fill_opacity=0.6).add_to(m_clusters)\n    else:\n        folium.CircleMarker(location=[lat,lon], radius=5, popup=folium.Popup(popup, max_width=300),\n                           color='blue', fill=True, fill_color='blue', fill_opacity=0.6).add_to(m_clusters)\n\n# We are going to display the map containing the number of venues in each borough and the cluster they are part of\n\nembed_map(m_clusters)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results and Discussion <a name=\"results\"></a>"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"The results in the map shown at the end of our analysis section confirm our first hypothesis after looking at the map representing with markers all the venues.\n\nIn our analysis we were looking for boroughs in Paris that had the highest number of groceries, pharmacies and metro and train stations because our client wanted to have the three of those venues nearby when deciding a borough to live in.\n\nThe central and northern boroughs seem to be the most crowded with the venues we picked for our analysis due to probably the higher development and higher population in the past and nowadays due to tourism as well for the central boroughs and the higher density of population nowadays in the north-western boroughs.\n\nIt would be interesting to look for a validation of our hypothesis of correlation between our results and the score of population or number of tourist attendance in each of the parisian boroughs. "},{"metadata":{},"cell_type":"markdown","source":"## Conclusion <a name=\"conclusion\"></a>"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"We can conclude that our analysis shows us that there are more grocery, pharmacy, and metro stations venues in the central boroughs in overall as it might happen in other major cities in the world.\n\nIn the particular case of the city of Paris, some north-western boroughs are also show high density in those type of venues which might indicate that those areas are higher in population in comparison to other parisian boroughs."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":4}